<!doctype html>
<html>
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Dataset Playbook</title>
  <style>
:root { --fg:#111; --muted:#666; --bg:#fff; --card:#f7f8fa; --link:#0b57d0; }
body { font-family: Inter, system-ui, -apple-system, Segoe UI, Roboto, sans-serif; color:var(--fg); background:var(--bg); max-width: 900px; margin: 32px auto; padding: 0 16px; line-height: 1.6; }
a { color: var(--link); }
code { background:#f1f3f4; padding:2px 6px; border-radius:6px; }
pre code { display:block; padding:12px; overflow:auto; }
.meta { color: var(--muted); }
hr { border:0; border-top:1px solid #e5e7eb; margin: 24px 0; }
</style>
</head>
<body>
  <p><a href="./index.html">‚Üê AI OSINT Home</a></p>
  <h1 id="dataset-playbook">Dataset Playbook</h1>
<p><strong>Human-readable HTML:</strong> https://carcipization.github.io/ai-osint/dataset-playbook.html
<strong>LLM-friendly Markdown:</strong> https://carcipization.github.io/ai-osint/dataset-playbook.md</p>
<p><strong>Dateline:</strong> 2026-02-27<br />
<strong>Status:</strong> Living guide</p>
<h2 id="quickstart-for-agents">Quickstart (for agents)</h2>
<ol>
<li>Define one falsifiable claim.</li>
<li>Use 3-source minimum: primary + independent corroborator + context/control.</li>
<li>Test one null explanation.</li>
<li>Publish with confidence + caveats.</li>
<li>Log gaps and next checks.</li>
</ol>
<h2 id="claim-format">Claim format</h2>
<p>Use one of these:</p>
<ul>
<li>"Did X change in window Y?"</li>
<li>"Did behavior shift after event Z?"</li>
<li>"Is X an anomaly vs baseline?"</li>
</ul>
<p>Reject broad prompts until a measurable claim exists.</p>
<h2 id="triangulation-minimum">Triangulation minimum</h2>
<p>For each claim:</p>
<ul>
<li><strong>Primary:</strong> closest to ground truth.</li>
<li><strong>Corroborator:</strong> different collection method.</li>
<li><strong>Control/context:</strong> confounder check (seasonality, policy, weather, outages, etc.).</li>
</ul>
<h2 id="confidence-labels">Confidence labels</h2>
<ul>
<li><strong>High:</strong> independent sources converge; key confounders tested.</li>
<li><strong>Medium:</strong> strong signal; one major uncertainty remains.</li>
<li><strong>Low:</strong> preliminary indicator; multiple unresolved uncertainties.</li>
<li><strong>False/Misleading:</strong> contradicted by stronger evidence.</li>
</ul>
<p>Include one-line rationale for the label.</p>
<h2 id="failure-modes-fast-checks">Failure modes (fast checks)</h2>
<ul>
<li><strong>Cadence mismatch</strong> (daily claim, monthly data).</li>
<li><strong>Schema/taxonomy drift</strong> (definitions changed mid-series).</li>
<li><strong>Coverage illusion</strong> (probe/sensor/reporting dropouts).</li>
<li><strong>Backfill/revision shock</strong> (history rewritten).</li>
<li><strong>Narrative overfit</strong> (story picked before test).</li>
</ul>
<h2 id="weirdobscure-source-trade-offs">Weird/obscure source trade-offs</h2>
<h3 id="behavioral-derivatives">Behavioral derivatives</h3>
<p>Examples: AIS/ADS-B inferred behaviors, anchorage states.</p>
<ul>
<li><strong>Pro:</strong> early signal.</li>
<li><strong>Con:</strong> inference errors.</li>
<li><strong>Use:</strong> trigger + corroborate, not standalone proof.</li>
</ul>
<h3 id="technical-side-effects">Technical side-effects</h3>
<p>Examples: OONI interference measurements.</p>
<ul>
<li><strong>Pro:</strong> direct mechanism clues.</li>
<li><strong>Con:</strong> probe-distribution bias.</li>
<li><strong>Use:</strong> pair with independent reporting/official statements.</li>
</ul>
<h3 id="research-corpora-snapshots">Research corpora snapshots</h3>
<p>Examples: TGDataset.</p>
<ul>
<li><strong>Pro:</strong> strong historical/graph baselines.</li>
<li><strong>Con:</strong> not live; scope constraints.</li>
<li><strong>Use:</strong> structure/context, not real-time truth.</li>
</ul>
<h3 id="aggregator-mega-feeds">Aggregator mega-feeds</h3>
<p>Examples: OpenSanctions, GDELT, OpenCorporates.</p>
<ul>
<li><strong>Pro:</strong> broad discovery speed.</li>
<li><strong>Con:</strong> inherited upstream errors/latency.</li>
<li><strong>Use:</strong> discovery/prioritization; verify against primaries before strong claims.</li>
</ul>
<h2 id="strategy-mode">Strategy mode</h2>
<p>For exploratory "find me a story in the data" work, use:
- <code>dataset-strategy.md</code></p>
<p>Use this playbook for claim verification and publication discipline.</p>
<h2 id="publish-checklist">Publish checklist</h2>
<ul>
<li>[ ] Claim is specific and measurable.</li>
<li>[ ] Time window stated.</li>
<li>[ ] 2+ independent sources used.</li>
<li>[ ] Null explanation tested.</li>
<li>[ ] Caveats listed.</li>
<li>[ ] Confidence label + rationale included.</li>
<li>[ ] Follow-up gaps logged.</li>
</ul>
<h2 id="maintenance-rules">Maintenance rules</h2>
<ul>
<li>Keep this file terse.</li>
<li>Add newly discovered failure modes immediately.</li>
<li>Move long examples/case studies to separate docs.</li>
</ul>
</body>
</html>
